{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from interp_max_utils_heuristic import compute_heuristic_independence_attention_copying, print_independence_attention_copying_stats\n",
    "from train_max_of_2 import get_model\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    TRAIN_IF_NECESSARY = False\n",
    "    model = get_model(train_if_necessary=TRAIN_IF_NECESSARY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418d0e135bef4578bb94ab55e9a04c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51a13bc79224cd1b0ba8892d7863eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea23799829e64c7ea533aa962aed29f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    results = compute_heuristic_independence_attention_copying(model, tqdm=tqdm)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume that attention paid to the non-max tokens is independent of the copying behavior on non-max tokens which are at least 1 away\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6f7e0c734c4eaca04f626a2eaf4697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then we expect that in 4.575402635964565e-05% of cases (0.18740849196910858 out of 4096), the model will return an incorrect result\n",
      "(The true accuracy is 1.0 (1 - acc = 0.0), i.e., 0 wrong out of 4096)\n",
      "The best possible heuristic loss is 0.00012142978523379791 (true loss: 1.763934704968051e-07)\n",
      "The worst-case logit gap is -2.6940298080444336\n",
      "Broken out by gap:\n",
      "Gap 0:\n",
      "Loss on gap 0 is 1.7829576393069146e-07\n",
      "Loss contribution on gap 0 is 1.3052398530797325e-10\n",
      "Gap 1:\n",
      "Loss on gap 1 is 0.005073419381013681\n",
      "Loss contribution on gap 1 is 0.00012064923697299874\n",
      "We expect that in 0.0019240019610151649% of cases (0.24242424964904785 out of 126), the model will return an incorrect result\n",
      "The worst-case logit gap is -2.6940298080444336\n",
      "Gap 2:\n",
      "Loss on gap 2 is 3.218162602166115e-05\n",
      "Loss contribution on gap 2 is 7.645639326385226e-07\n",
      "Gap 3:\n",
      "Loss on gap 3 is 1.3846764778817142e-07\n",
      "Loss contribution on gap 3 is 3.2849320725735215e-09\n",
      "Gap 4:\n",
      "Loss on gap 4 is 4.111777567574619e-08\n",
      "Loss contribution on gap 4 is 9.735747123077715e-10\n",
      "Gap 5:\n",
      "Loss on gap 5 is 2.736017804482352e-08\n",
      "Loss contribution on gap 5 is 6.462615261548381e-10\n",
      "Gap 6:\n",
      "Loss on gap 6 is 2.1881258723879213e-08\n",
      "Loss contribution on gap 6 is 5.153448905617141e-10\n",
      "Gap 7:\n",
      "Loss on gap 7 is 1.8354941616865097e-08\n",
      "Loss contribution on gap 7 is 4.308238035071282e-10\n",
      "Gap 8:\n",
      "Loss on gap 8 is 1.7587183821475253e-08\n",
      "Loss contribution on gap 8 is 4.111937652257437e-10\n",
      "Gap 9:\n",
      "Loss on gap 9 is 1.7142240161131107e-08\n",
      "Loss contribution on gap 9 is 3.990261109981447e-10\n",
      "Gap 10:\n",
      "Loss on gap 10 is 1.5830541716566607e-08\n",
      "Loss contribution on gap 10 is 3.666824553446123e-10\n",
      "Gap 11:\n",
      "Loss on gap 11 is 1.502815356875549e-08\n",
      "Loss contribution on gap 11 is 3.462058620913428e-10\n",
      "Gap 12:\n",
      "Loss on gap 12 is 1.4741118292505207e-08\n",
      "Loss contribution on gap 12 is 3.375699901811336e-10\n",
      "Gap 13:\n",
      "Loss on gap 13 is 1.3807579094383449e-08\n",
      "Loss contribution on gap 13 is 3.1413884995800555e-10\n",
      "Gap 14:\n",
      "Loss on gap 14 is 1.4197834895605434e-08\n",
      "Loss contribution on gap 14 is 3.20744005293978e-10\n",
      "Gap 15:\n",
      "Loss on gap 15 is 1.377280772876289e-08\n",
      "Loss contribution on gap 15 is 3.087790898194462e-10\n",
      "Gap 16:\n",
      "Loss on gap 16 is 1.3263455979607966e-08\n",
      "Loss contribution on gap 16 is 2.949322660180029e-10\n",
      "Gap 17:\n",
      "Loss on gap 17 is 1.2179899241059505e-08\n",
      "Loss contribution on gap 17 is 2.684693658208463e-10\n",
      "Gap 18:\n",
      "Loss on gap 18 is 1.162828281252255e-08\n",
      "Loss contribution on gap 18 is 2.5391645187941013e-10\n",
      "Gap 19:\n",
      "Loss on gap 19 is 1.151344356855141e-08\n",
      "Loss contribution on gap 19 is 2.4890657421946107e-10\n",
      "Gap 20:\n",
      "Loss on gap 20 is 1.1400872102831515e-08\n",
      "Loss contribution on gap 20 is 2.438647377412945e-10\n",
      "Gap 21:\n",
      "Loss on gap 21 is 1.0937183873192495e-08\n",
      "Loss contribution on gap 21 is 2.313192370691449e-10\n",
      "Gap 22:\n",
      "Loss on gap 22 is 1.0810311770968377e-08\n",
      "Loss contribution on gap 22 is 2.259155335555365e-10\n",
      "Gap 23:\n",
      "Loss on gap 23 is 1.03771278438878e-08\n",
      "Loss contribution on gap 23 is 2.1413271676397316e-10\n",
      "Gap 24:\n",
      "Loss on gap 24 is 1.059866570337843e-08\n",
      "Loss contribution on gap 24 is 2.15794575311283e-10\n",
      "Gap 25:\n",
      "Loss on gap 25 is 8.978638451405804e-09\n",
      "Loss contribution on gap 25 is 1.8024238747045644e-10\n",
      "Gap 26:\n",
      "Loss on gap 26 is 9.014493821281993e-09\n",
      "Loss contribution on gap 26 is 1.7828124790671403e-10\n",
      "Gap 27:\n",
      "Loss on gap 27 is 9.022972962863363e-09\n",
      "Loss contribution on gap 27 is 1.7566228933466144e-10\n",
      "Gap 28:\n",
      "Loss on gap 28 is 9.135733019677964e-09\n",
      "Loss contribution on gap 28 is 1.7493156427229264e-10\n",
      "Gap 29:\n",
      "Loss on gap 29 is 9.034270175455257e-09\n",
      "Loss contribution on gap 29 is 1.699919294315508e-10\n",
      "Gap 30:\n",
      "Loss on gap 30 is 9.316396306632173e-09\n",
      "Loss contribution on gap 30 is 1.7210354176440063e-10\n",
      "Gap 31:\n",
      "Loss on gap 31 is 9.383926327346773e-09\n",
      "Loss contribution on gap 31 is 1.7002355534541187e-10\n",
      "Gap 32:\n",
      "Loss on gap 32 is 9.508419600361898e-09\n",
      "Loss contribution on gap 32 is 1.6879881062135874e-10\n",
      "Gap 33:\n",
      "Loss on gap 33 is 9.60495260826461e-09\n",
      "Loss contribution on gap 33 is 1.6688693049910714e-10\n",
      "Gap 34:\n",
      "Loss on gap 34 is 1.0057361449604158e-08\n",
      "Loss contribution on gap 34 is 1.70836174879463e-10\n",
      "Gap 35:\n",
      "Loss on gap 35 is 1.0303778379176069e-08\n",
      "Loss contribution on gap 35 is 1.7089676347233367e-10\n",
      "Gap 36:\n",
      "Loss on gap 36 is 1.0349621330312146e-08\n",
      "Loss contribution on gap 36 is 1.673952754513792e-10\n",
      "Gap 37:\n",
      "Loss on gap 37 is 1.075531182681821e-08\n",
      "Loss contribution on gap 37 is 1.6940501905116075e-10\n",
      "Gap 38:\n",
      "Loss on gap 38 is 1.0931149576415041e-08\n",
      "Loss contribution on gap 38 is 1.674232394173195e-10\n",
      "Gap 39:\n",
      "Loss on gap 39 is 9.699701527447009e-09\n",
      "Loss contribution on gap 39 is 1.4423512977764817e-10\n",
      "Gap 40:\n",
      "Loss on gap 40 is 9.716405469271915e-09\n",
      "Loss contribution on gap 40 is 1.4003787165175024e-10\n",
      "Gap 41:\n",
      "Loss on gap 41 is 1.01544188134127e-08\n",
      "Loss contribution on gap 41 is 1.4158854014401171e-10\n",
      "Gap 42:\n",
      "Loss on gap 42 is 1.0270115399102942e-08\n",
      "Loss contribution on gap 42 is 1.3826781918859994e-10\n",
      "Gap 43:\n",
      "Loss on gap 43 is 1.0604008056116217e-08\n",
      "Loss contribution on gap 43 is 1.3754741416128055e-10\n",
      "Gap 44:\n",
      "Loss on gap 44 is 1.0764598225642832e-08\n",
      "Loss contribution on gap 44 is 1.3421271122289862e-10\n",
      "Gap 45:\n",
      "Loss on gap 45 is 1.162429181853327e-08\n",
      "Loss contribution on gap 45 is 1.3894794278879104e-10\n",
      "Gap 46:\n",
      "Loss on gap 46 is 1.1675820770233896e-08\n",
      "Loss contribution on gap 46 is 1.3342039885458984e-10\n",
      "Gap 47:\n",
      "Loss on gap 47 is 1.2195482286035197e-08\n",
      "Loss contribution on gap 47 is 1.3280219546469513e-10\n",
      "Gap 48:\n",
      "Loss on gap 48 is 1.2910380917722338e-08\n",
      "Loss contribution on gap 48 is 1.3349863137835143e-10\n",
      "Gap 49:\n",
      "Loss on gap 49 is 1.3651091042750825e-08\n",
      "Loss contribution on gap 49 is 1.335066210829058e-10\n",
      "Gap 50:\n",
      "Loss on gap 50 is 1.4132674324676186e-08\n",
      "Loss contribution on gap 50 is 1.3013363414353415e-10\n",
      "Gap 51:\n",
      "Loss on gap 51 is 1.5002444405550266e-08\n",
      "Loss contribution on gap 51 is 1.2939059161997737e-10\n",
      "Gap 52:\n",
      "Loss on gap 52 is 1.6112451371852907e-08\n",
      "Loss contribution on gap 52 is 1.2938027158492795e-10\n",
      "Gap 53:\n",
      "Loss on gap 53 is 1.7425524698586873e-08\n",
      "Loss contribution on gap 53 is 1.293599644191856e-10\n",
      "Gap 54:\n",
      "Loss on gap 54 is 1.8704908020978308e-08\n",
      "Loss contribution on gap 54 is 1.2730394711385996e-10\n",
      "Gap 55:\n",
      "Loss on gap 55 is 1.4865049201438927e-08\n",
      "Loss contribution on gap 55 is 9.181834014431988e-11\n",
      "Gap 56:\n",
      "Loss on gap 56 is 9.838176128675311e-09\n",
      "Loss contribution on gap 56 is 5.4466476554251124e-11\n",
      "Gap 57:\n",
      "Loss on gap 57 is 1.1299509990704627e-08\n",
      "Loss contribution on gap 57 is 5.518954481642199e-11\n",
      "Gap 58:\n",
      "Loss on gap 58 is 1.2262097178049118e-08\n",
      "Loss contribution on gap 58 is 5.175596928417968e-11\n",
      "Gap 59:\n",
      "Loss on gap 59 is 1.3872010728640993e-08\n",
      "Loss contribution on gap 59 is 4.9189276696086976e-11\n",
      "Gap 60:\n",
      "Loss on gap 60 is 1.736881495162379e-08\n",
      "Loss contribution on gap 60 is 4.9668326064992994e-11\n",
      "Gap 61:\n",
      "Loss on gap 61 is 2.143442976549046e-08\n",
      "Loss contribution on gap 61 is 4.6338616691957554e-11\n",
      "Gap 62:\n",
      "Loss on gap 62 is 3.095845128459981e-08\n",
      "Loss contribution on gap 62 is 4.497304302187243e-11\n",
      "Gap 63:\n",
      "Loss on gap 63 is 1.8626450382086546e-09\n",
      "Loss contribution on gap 63 is 1.3635761626710502e-12\n",
      "Bad gap loss contribution is 0.00012064923697299874\n",
      "Good gap loss contribution is 7.805482607991784e-07\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print_independence_attention_copying_stats(model, tqdm=tqdm, results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
